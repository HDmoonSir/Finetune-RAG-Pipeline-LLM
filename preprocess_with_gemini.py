import os
import json
import glob
import google.generativeai as genai
from tqdm import tqdm
import math
import argparse
import typing as tp

# 1. Gemini API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
try:
    api_key = os.environ.get("GEMINI_API_KEY")
    if not api_key:
        raise ValueError("GEMINI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    genai.configure(api_key=api_key)
except (ValueError, KeyError) as e:
    print(f"API í‚¤ ì„¤ì • ì˜¤ë¥˜: {e}")
    exit()

def generate_qa_pairs(prompt_content: str) -> tp.Optional[tp.List[tp.Dict[str, str]]]:
    """Gemini ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ Q&A ìŒì„ ìƒì„±í•©ë‹ˆë‹¤."""
    model = genai.GenerativeModel(
        'gemini-1.5-flash',
        generation_config=genai.types.GenerationConfig(response_mime_type="application/json")
    )
    try:
        response = model.generate_content(prompt_content)
        json_text = response.text.strip()
        if json_text.startswith("```json"):
            json_text = json_text[7:-4].strip()
        json_data = json.loads(json_text)
        return json_data.get('qa_pairs', [])
    except (json.JSONDecodeError, AttributeError, ValueError) as e:
        print(f"-- Q&A ìƒì„± ì˜¤ë¥˜: {e}")
        return None
    except Exception as e:
        print(f"-- ì˜ˆê¸°ì¹˜ ì•Šì€ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

def generate_unsupervised_text(prompt_content: str) -> tp.Optional[str]:
    """Gemini ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ë¹„ì§€ë„ í•™ìŠµìš© í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    model = genai.GenerativeModel('gemini-1.5-flash')
    try:
        response = model.generate_content(prompt_content)
        return response.text
    except Exception as e:
        print(f"-- í…ìŠ¤íŠ¸ ìƒì„± ì˜¤ë¥˜: {e}")
        return None

def format_for_llama3(qa_pairs: tp.List[tp.Dict[str, str]]) -> tp.List[tp.Dict[str, str]]:
    """Q&A ìŒì„ Llama 3ì˜ Instruction Fine-tuning í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    formatted_data = []
    for pair in qa_pairs:
        if 'question' not in pair or 'answer' not in pair or not pair['question'] or not pair['answer']:
            continue
        instruction = pair['question']
        response = pair['answer']
        formatted_string = (
            f"<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n"
            f"{instruction}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n"
            f"{response}<|eot_id|>")
        formatted_data.append({"text": formatted_string})
    return formatted_data

def main() -> None:
    parser = argparse.ArgumentParser(description="Geminië¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ ë°ì´í„°ì…‹ì„ ìƒì„±í•©ë‹ˆë‹¤.")
    parser.add_argument(
        '--mode',
        type=str,
        default='qa',
        choices=['qa', 'unsupervised'],
        help='ìƒì„± ëª¨ë“œë¥¼ ì„ íƒí•©ë‹ˆë‹¤. `qa`ëŠ” ì§ˆì˜ì‘ë‹µ ìŒì„, `unsupervised`ëŠ” ë¹„ì§€ë„í•™ìŠµìš© í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.'
    )
    args = parser.parse_args()

    print(f"ğŸš€'{args.mode}' ëª¨ë“œë¡œ ë°ì´í„° ìƒì„±ì„ ì‹œì‘í•©ë‹ˆë‹¤.")

    jsonl_paths: tp.List[str] = glob.glob("data/**/*.jsonl", recursive=True) + glob.glob("data/*.jsonl")
    jsonl_paths = sorted(list(set(jsonl_paths)))

    if not jsonl_paths:
        print("ì²˜ë¦¬í•  JSONL íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    all_pages_by_pdf: tp.Dict[str, tp.List[tp.Dict[str, tp.Any]]] = {}
    for path in jsonl_paths:
        with open(path, 'r', encoding='utf-8') as f:
            for line in f:
                try:
                    data: tp.Dict[str, tp.Any] = json.loads(line)
                    source_pdf: tp.Optional[str] = data.get('source_pdf')
                    if source_pdf:
                        if source_pdf not in all_pages_by_pdf:
                            all_pages_by_pdf[source_pdf] = []
                        all_pages_by_pdf[source_pdf].append(data)
                except json.JSONDecodeError:
                    print(f"âš ï¸ Warning: {path} íŒŒì¼ì˜ ì¼ë¶€ ë¼ì¸ì—ì„œ JSON ë””ì½”ë”© ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

    for pdf in all_pages_by_pdf:
        all_pages_by_pdf[pdf].sort(key=lambda x: x.get('page_number', 0))

    all_generated_data: tp.List[tp.Any] = []
    total_api_calls: int = 0
    TEXT_PAGE_BATCH_SIZE: int = 15

    qa_prompt_template: str = """ì•„ë˜ [ë¬¸ì„œ ë‚´ìš©]ì€ '---'ë¡œ êµ¬ë¶„ëœ ì—¬ëŸ¬ í…ìŠ¤íŠ¸ ì„¹ì…˜ì„ í¬í•¨í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì´ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ, ë‹¤ì–‘í•˜ê³  í•µì‹¬ì ì¸ Q&A ìŒ 25ê°œë¥¼ \"qa_pairs\"ë¥¼ í‚¤ë¡œ í•˜ëŠ” JSON ë°°ì—´ í˜•ì‹ìœ¼ë¡œ ìƒì„±í•´ ì£¼ì„¸ìš”. ì§ˆë¬¸ê³¼ ë‹µë³€ì€ ëª¨ë‘ í•œêµ­ì–´ë¡œ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤. ì¶œë ¥ì€ ì˜¤ì§ JSON ë°°ì—´ì´ì–´ì•¼ í•©ë‹ˆë‹¤.

[ë¬¸ì„œ ë‚´ìš©]
{text}"""
    unsupervised_prompt_template: str = """ì•„ë˜ [ë¬¸ì„œ ë‚´ìš©]ì€ '---'ë¡œ êµ¬ë¶„ëœ ì—¬ëŸ¬ í…ìŠ¤íŠ¸ ì„¹ì…˜ì„ í¬í•¨í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì´ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ, ë¬¸ì„œì˜ í•µì‹¬ ì£¼ì œì™€ ì •ë³´ë¥¼ í¬ê´„í•˜ëŠ” ìƒì„¸í•˜ê³  êµ¬ì¡°í™”ëœ ìš”ì•½ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•´ ì£¼ì„¸ìš”. ì›ë³¸ì˜ ì „ë¬¸ì ì¸ ìŠ¤íƒ€ì¼ê³¼ í†¤ì„ ìœ ì§€í•˜ë©°, ì—¬ëŸ¬ ë‹¨ë½ìœ¼ë¡œ êµ¬ì„±ëœ ê°€ë…ì„± ë†’ì€ ê¸€ì„ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤. ì¶œë ¥ì€ ì˜¤ì§ ìƒì„±ëœ í…ìŠ¤íŠ¸ì—¬ì•¼ í•©ë‹ˆë‹¤.

[ë¬¸ì„œ ë‚´ìš©]
{text}"""

    for pdf_name, pages in all_pages_by_pdf.items():
        print(f"\nğŸ“„ {pdf_name} ë¬¸ì„œ ì²˜ë¦¬ ì¤‘...")
        page_texts: tp.List[str] = [p['text'] for p in pages if p.get('text') and len(p['text'].strip()) > 50]
        if not page_texts:
            continue

        num_batches: int = math.ceil(len(page_texts) / TEXT_PAGE_BATCH_SIZE)
        for i in tqdm(range(num_batches), desc=f"{os.path.basename(pdf_name)} ì²˜ë¦¬ ì§„í–‰ë¥ "):
            batch_texts: tp.List[str] = page_texts[i * TEXT_PAGE_BATCH_SIZE : (i + 1) * TEXT_PAGE_BATCH_SIZE]
            combined_text: str = "\n\n---\n\n".join(batch_texts)

            if args.mode == 'qa':
                prompt: str = qa_prompt_template.format(text=combined_text)
                result: tp.Optional[tp.List[tp.Dict[str, str]]] = generate_qa_pairs(prompt)
                if result:
                    all_generated_data.extend(result)
            else: # unsupervised
                prompt = unsupervised_prompt_template.format(text=combined_text)
                result: tp.Optional[str] = generate_unsupervised_text(prompt)
                if result:
                    all_generated_data.append({"text": result})
            
            total_api_calls += 1

    print(f"\nTotal API calls made: {total_api_calls}")
    print(f"Total items generated before processing: {len(all_generated_data)}")

    if args.mode == 'qa':
        unique_qa_pairs: tp.List[tp.Dict[str, str]] = []
        processed_questions: tp.Set[str] = set()
        for pair in all_generated_data:
            question: tp.Optional[str] = pair.get('question')
            if question and question not in processed_questions:
                unique_qa_pairs.append(pair)
                processed_questions.add(question)
        final_data: tp.List[tp.Dict[str, str]] = format_for_llama3(unique_qa_pairs)
        output_file: str = 'gemini_generated_qa_dataset.jsonl'
        print(f"Total unique Q&A pairs after deduplication: {len(unique_qa_pairs)}")
    else:
        final_data = all_generated_data
        output_file = 'gemini_generated_unsupervised_dataset.jsonl'

    with open(output_file, 'w', encoding='utf-8') as f:
        for item in final_data:
            f.write(json.dumps(item, ensure_ascii=False) + '\n')

    print(f"\nâœ… All data has been saved to '{output_file}'.")
    print(f"Total final records created: {len(final_data)}")

if __name__ == "__main__":
    main()