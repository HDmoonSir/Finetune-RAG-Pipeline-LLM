# configs/eval/default_eval.yaml

# Evaluation settings
eval_dataset_path: "data_result/gemini_generated_qa_dataset.jsonl"
num_samples: 10 # 0으로 설정하면 전체 데이터셋 사용

# Model settings (RAG 파이프라인과 공유)
model:
  model_type: "api"
  model_id: "gemini-1.5-flash-latest"
  unsupervised_lora_path: null # 비지도학습 LoRA 어댑터 경로
  sft_lora_path: null # 지도학습 LoRA 어댑터 경로
  embedding_model_id: "sentence-transformers/all-MiniLM-L6-v2"

# Knowledge base settings
knowledge_base_settings:
  knowledge_base: "default"
  text_splitter_chunk_size: 1000
  text_splitter_chunk_overlap: 100
  retriever_search_k: 3
  default_knowledge_base_dataset: "squad_kor_v1"

# Generation settings
generation:
  max_new_tokens: 512
  temperature: 0.1
  rag_prompt_template: |
    다음 컨텍스트 정보를 사용하여 질문에 답변해 주세요.
    만약 컨텍스트에 답변이 없다면, 모른다고 답해 주세요.

    컨텍스트:
    {context}

    질문:
    {question}

    답변:
  model_max_seq_length: 2048 # Default for local-quantized models
